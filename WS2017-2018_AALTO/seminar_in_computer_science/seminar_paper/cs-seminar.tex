\documentclass[article]{aaltoseries}
\usepackage[utf8]{inputenc}
\usepackage{algorithm}
\usepackage{algorithmic}


\begin{document}
 
%=========================================================

\title{Training deep neural network on mobile devices}

\author{Dongmin Wu
\\\textnormal{\texttt{dongmin.wu@aalto.fi}}} % Your Aalto e-mail address

\affiliation{\textbf{Tutor}: Jukka K. Nurminen} % First and last name of your tutor

\maketitle

%==========================================================

\begin{abstract}


  Since the Deep learning(DL) technology was published, this technology has been
  implemented in various fields and obtained exciting results. 
  However, this technology has essential requirement of computational resources, especially
  in training phase. In addition, the large number of mobile devices makes the implementation
  of DL on mobile devices a promising topic. 
 According to the high dependency on computation resources,
 Mobile computing devices, such as mobile phone,
  wearable devices and tablet can rarely directly execute the training phase of DL. 
 Currently, there are already some solutions for implementing DL on mobile\cite{Ota:2017},
 but most of them are focusing on the predicting phase of DL. 
 Thus in this paper, we are focusing on the training phase of DL on mobile devices.
 This paper lists two major solutions currently used in implementing training phase of DL on mobile service;
 briefly introduces the features of both and talks about the scenario of the appliance. 


\vspace{3mm}
\noindent KEYWORDS: Deep learning, Mobile devices, Training phase, Knowledge Distillation, Federal Learning

\end{abstract}


%============================================================


\section{Introduction}


Deep learning has been widely used recently. As the primary algorithm of Deep learning technology,
 the popularity of neural network algorithm 
 has considerably increased and become the state-of-art for solving different pattern recognition
problems.
The Deep learning technology can acquire 
  dependable abstractions from various data, which has benefited different applications, 
  including motion detection, natural language processing and image recognition. 

When talking about the training phase of the neural network, the computational cost always a considerable
issue to get over. For example, a typical Convolutional Neural Network (AlexNet \cite{NIPS2012_4824}) 
spends approximately 2.6 minutes in a forward process for one image on a mobile device\cite{lane2015early}.
Due to the high computation requirement, training the DL mainly run on the Graphics Processing Unit(GPU) or specialised processors, 


Whereas, training the neural network widely utilises on mobile devices, 
such as mobile phones, wearable devices and vehicle electronics. 
One of the typical scenarios is the speech to text software; current approaches are using some the general 
pattern to distill the text from user's voice. Although these methods have good accuracy when users have
a \"standard\" accent, they are not good enough for people have has their accent. This issue will be
fixed if the application allows users to train the existed neural network, generating a new pattern based on 
the specific user.

In addition, the requirement of privacy drives the need for training neural network on mobile devices.
In most current approaches of neural networks, the server which performs the training phase need to obtain
the raw data of users. But in some cases, these data may be too sensitive for users. For example, the keyboard
application can adjust the prediction of words based on users history and custom. But those data are too 
private to upload to the server. In this cases, training the neural network on mobile is necessary instead of 
traditional training on the server.


Thus, training the neural network on mobile devices is a promising topic but have apparent barriers. 
Mobile devices have even less computational resources than 
servers and large computers. On the other hand, mobile devices can hardly afford the energy consumption
of standard Deep learning algorithms. 

Ota et al.\cite{Ota:2017} comprehensively listed different Deep learning algorithms,
reviewed some software frameworks and hardware platforms for executing prediction phase of neural networks on mobile devices.
At last, they presented some applications running on mobile devices integrated with Deep learning technology. 
But they didn't mention the performance of training a neural network on mobile devices. 

This paper will analyse the characteristics of Deep learning and neural network algorithms;
list the different methods of training neural network on mobile devices and introduce those methods briefly. 
At last, this paper will give a conclusion by supposing some scenarios of the appliance.

In section \ref{sec:background}, we will introduce some background knowledge about neural network and mobile devices.
Section \ref{sec:related_works} shows some related works in the field of training Deep neural networks on mobile devices.
We present two main approaches currently used and introduces the particular method in section \ref{sec:approaches}.
Finally, we conclude and raise some possible future works.




%============================================================


\section{Background}
\label{sec:background}

In this section, the Deep learning and mobile devices will be introduced. This fundamental 
knowledge helps us to understand the context of this paper better.


%------------------------------------------------------------


\subsection{Deep Learning and neural network}

The neural network in Deep learning can be called Deep Neural Network(DNN), which is one of the most promising 
parts of current machine learning methods. 

\subsubsection{History of Deep Neural Network}

% 1. history  1page
In the mid-19th a paper was already introduced an Artificial Neural Network (ANN)\cite{Warren1943}, 
McCulloch et al. developed the first simple ANN which mimics the neural network system of the human brain. This ANN is not
able to learn models from data, but following research extended the capabilities of ANN and generated an unsupervised 
learning algorithm and supervised algorithm subsequently.

In the 1970s and 1980s, a back-propagation learning algorithm was found. Because of efficiency, the application of back-propagation
reached its peak in the mid-80s. LeCun applied this algorithm to the convolutional neural network 
for the first time in 1989, which had a significant impact on the Deep learning. After that, the Cresceptron Model was introduced, 
the using of max-pooling layers in the neural network architecture was widely used in the modern Deep learning technology.

After the year of 2010, Deep learning has another wave of popularity because there are more affordable Graphics Processing Units(GPU)
 with powerful parallel computation capacities. AlexNet\cite{NIPS2012_4824} earned the first prize of 
the 2012 ImageNet Large-Scale Visual Recognition Challenge (ILSVRC). 

From then on, the researching of DNN has considerably accelerated. Google, Facebook, Apple and Amazon have published
their papers in this area. In 2015, Google introduced their GoogLeNet\cite{GoogLeNet}, whose Inception model composed the convolutional 
neural network in a new way such that no sequentially arranged layers are possible. In the same year, the ResNet\cite{ResNet} of Microsoft won 
the ILSVRC with the error rate of 3.6\%, which is smaller than the error rate of human beings.




\subsubsection{Characteristic of Deep Neural Network}
% 2. characteristic 1page

The Deep Neural Network has the higher hierarchy than ANNs, which means a large number of hidden layers\cite{MAL-006}. 
This difference makes DNN understand more complex models than ANN, which means the Deep learning or especially DNN
has better behavior on describing non-linear objects, including image, voice, text and bioinformatics.

Furthermore, compared to Machine learning technology, deep learning is more suitable for various tasks. The basic concept
of DNN is a multi-layer neural network; the algorithm will produce a pattern by itself only relies on a large data set.
On the contrary, previous machine learning algorithms specifically are designed for the specific tasks. 
With DNN technology, users can tackle different issues with one implementation of DNN. 

As the widely used of Big data technology, the traditional machine learning technologies such as Support Vector Machine (SVM) are
not such suitable for processing a significant amount of data. On the other hand, because of the discovery of back-propagation
algorithm, the efficiency of DNNs is relatively higher than traditional Machine learning algorithms.

DNN is more flexible than traditional machine learning approaches as well. 
Since the DNN consists of multiple neutrons, the number of neutrons can be adjusted
according to the requirement of different task. This characteristic allows DNN has a vast potential of applying. So far, 
DNN has already impacted our life, services, e.g., Google translate, AlphaGo and Siri are the examples of successful applications.






%------------------------------------------------------------


\subsection{Current mobile devices} %2 pages

In this paper, the mobile devices are considered as a group of electronic devices with
computational units that has good mobility and provides the interactive features to human beings.
As the range of mobile is quite large, in this paper, we explicitly discuss three representative 
mobile devices: Mobile phone, wearable devices and vehicle devices.




%history fo mobile devices
\subsubsection{History of mobile devices}

As the most common mobile devices in our daily life, the mobile phone is one of the most common 
electronics to regular people. For example, there are nearly 300,000 mobile phones have been 
sold during the second quarter of 2016 \cite{moblePhoneSale}. In 1973 the first handheld mobile phone
was showed by John F. Mitchiell and Martin Copper in America. Since then the mobile phone 
changed the modern life. In 2007, Apple Inc. published the first multi-touch smartphone,
 which made the mobile computation true.
  Currently, almost all the mobile phones are in this form. 


Wearable devices, like Nike+, Google Glass and Apple watch are produced in the last decade. They present
a type of on-body electronics in addition to mobile phones. They mainly have specific features, some of them
are designed for monitoring body status while others have the limited interactive functionality.

The last category of mobile devices discussing in this paper is the vehicle devices. From the oldest vacuum tube
car radios to current automatic driving systems, electronics in vehicles acted a vital role while people are
driving. Along with the development of mobile electronic technologies, the vehicle devices are becoming more convenient
and computational.



\subsubsection{Characteristic of mobile devices}
\label{sec:characteristic_mobile_devices}

Because of the limited resources and specific usage, mobile devices, in general, do not have a high-performance 
universal computation core. Alternatively, they have some uniquely designed computation units like DSP processor,
baseband processor and coprocessors.

In mobile phones, the power of processors considerably increased in the past few years. But the limitation still existed, 
one of the leading reason is the energy consumption. Mobile phones have limited size and need meet the requirement continually
using, that limitation makes the computation capability of mobile phones is relatively lower than desktop computers.

As for other wearable devices, they have more limited battery capacity and slower speed. In addition to that, 
they have more real-time requirement than mobile phones. Most of them are required to be able to monitoring
movement immediately.

Vehicle devices have the most computation resources comparing to the other two. Currently, some self-driving
cars are existed in the market, such as Waymo, most of them are driven by Deep learning technology. 
But safety requirement of vehicle devices is highest compared to another two devices.  



%------------------------------------------------------------





\section{Related works}
\label{sec:related_works}

Implementing the training phase on mobile devices is relatively more difficult than the predicting phase.
Firstly, the training phase consists of more steps in each iteration. Popular neural networks, such
feed-forward neural network and convolutional neural network, use back-propagation\cite{le1988theoretical}
for calculating the gradient descent. Even though this approach has higher efficiency than usual,
the computational cost is far more than predicting phase.

Secondly, the training phase has more iterations than predicting phase. Training phase uses the gradient descent
for calculating the local optima of the loss function; commonly this algorithm needs about 20 to 50 repetition
for obtaining a small enough loss. However, the predicting phase only requires one iteration for each prediction.

To the best of our knowledge, except for hardware specific optimization like Apple's coreML\cite{AppleInc.},
 current solutions of squeezing the learning phase of Deep Learning on mobile devices 
are focusing on two directions: model compression and distributed learning.



\subsection{Model compression}


Since the principal issue of executing the training phase on mobile devices is the complexity of the neural network,
The most intuitive way of fixing this concern is to decrease the size and complexity. Thus, some approaches try
to compress the neural network in order fit the requirement of mobile devices.
The critical point of model compression is keeping the similar accuracy after the compression. Most of the approaches
are based on an existing complex neural network, and they are specifically designed for one or few problems. 


MobileNets\cite{MobileNets2017} is a compressed convolutional neural network discovered by Google. MobileNets developed 
from streamlined architecture; it performs nearly the same accuracy as the VGG16\cite{simonyan2014very} with 32 smaller
and 27 times less computational cost. MobileNets has general use cases, e.g., object detection and face detection.

Han et al.\cite{Han2015} presented an approach of compressing the neural network in 2016. 
They deployed a 3 stage pipeline: pruning, trained quantization and Huffman coding, which can decrease
the size of the neural network from 35x to 49x. In addition, they compressed network increases the speed from 3 times to 4
and had 3x to 7x better energy efficiency.

\subsection{Distributed Learning}

Because of a large number of mobile devices, the distributed learning is another functional approach to fixing the
issue of training neural network on the mobile devices.
One crucial problem with this approach is the privacy of the data. Because some data is sensitive to users, 
they are mostly not willing to share it with others. Another issue is the communication cost. Since the communication fee
is higher between mobile devices than desktop devices, the approaches have high communication cost is hard to be 
accepted by users.

Ananda et al.\cite{Suresh2016} show an optimization of the original naive distributed mean estimation algorithm, which uses 
stochastic binary rounding approach yields a mean squared error. They also improve the coding strategy to reduce the error.
Jeffery et al.\cite{NIPS2012_4687} achieve an algorithm which applies to any gradient-based 
machine learning algorithm named Downpour SGD.
Combining with Sandblaster, a framework, they can train a deep neural network 100x bigger than before.





%------------------------------------------------------------


\section{Detail introduction to two approaches}
\label{sec:approaches}


% TODO: explain that there already some approaches, but this two of them are most representative. 



As to last section shows, a large number of representative methods have been discovered in the model compression and distributed learning. 
In this section, two methods will be discussed:
Reducing the size of a mentee Neural Network and Increasing the capability through distributed computation.
These two ways are most famous in their area, and they are the most representative examples because they
aim to fix the critical problems in the respective field.

In section \ref{sub_sec:reduce_size}, we introduce an approach named \emph{Knowledge Distillation},
which can compress the neural network without sacrificing too much accuracy. This approach is more novel
than others since it doesn't follow the traditional method of quantizing the hidden layers.


In section \ref{sub_sec:federal_learning}, we present Google's solution of implementing the distributed
learning. This approach needs less communication cost compared to other existing strategies. Besides, they 
protect the privacy of each client node. This method has been applied to Google's Android keyboard application,
too.


\subsection{Reducing the size of a mentee Neural Network}
\label{sub_sec:reduce_size}


In 2014, \emph{Knowledge Distillation}, an approach to reducing the size of Neural Network, 
showed an idea of teaching a new simpler Neural Network with a well-trained complex Neural Network.
In that way, a representative Neural Network was formed, and the size is small enough for mobile training.

Figure \ref{fig:mentor_pic}\cite{Distillation:2015} shows the schematic of this mentee-mentor architecture. 

\begin{figure}[t!]
  \begin{center}
    % Note how the file extension has been removed from the filename below
    % so that the LaTeX command can automatically pick any supported file format
    \includegraphics[width=1\textwidth]{figures/mentor_mentee}
    \caption{The mentee network uses the outputs of mentor network as its input labels}
    \label{fig:mentor_pic}
  \end{center}
\end{figure}

As the figure shown, the mentee network has much fewer layers of Neural Network. 
Hinton et al.[reference], presented the Knowledge Distillation that makes neural network smaller by learning the 
output of the softmax layer\cite{SoftMax}. 

This idea was initially introduced by \cite{Caruana2006}, the paper showed 
the output of the softmax layer have much more information than a simple classifier. 
The softmax function is also able to show the correlations between
target labels. For example, in a computer image recognition neural network for classifying cat, dog and boat.
If the input of that network is a picture of a cat, the correlation of the output
between cat and dog is higher than cat versus boat because the appearance of a cat is more similar to a dog than a boat.
Hinton called those hidden information in the softmax output as \emph{Dark Knowledge}, 
as the knowledge is unused and ignored by conventional neural network classifier.

Base on the phenomenon above, a smaller mentee neural network can get a more accurate result with the regularization from
the Dark knowledge. 
The approach of \emph{Knowledge Distillation} mainly has two steps: target soften and distillation.

\subsubsection{Target soften}

Normally, for a data set \(X\), we can derive features \(\textbf x \) and correspond target labels \(\textbf y\).
In addition, we can get the predicted output vector \(\textbf y_{mentor}\) from the mentor network.
The parameters in the mentor network are \(\Theta_{mentor}\), 
the derivation of \(\textbf y_{mentor}\) can be represented as below:

%TODO: not sure the equation is correct
%TODO: add softmax function
\[
  \textbf y_{mentor} = softmax(\Theta_{mentor} \textbf{x})
\]

In the practical, the target labels are collected in a format named one-hot, a term comes from the digital
design field\cite{DigitalDesign}. For example, if \(X\) has three target labels: \emph{cat, dog} and \emph{car},
The target labels \(\textbf{y}\) will be presented in the following format:

\[
  cat:\ y = \{1,0,0\};\ 
  dog:\ y = \{0,1,0\};\ 
  car:\ y = \{0,0,1\};\ 
\]

The one-hot form above was defined as the \emph{hard target}, as they only reveal the classification result of input data.

However, a prediction of a well-trained mentor network \(\textbf y_{mentor}\) will show as a value between 
\(0\) and \(1\), because of the softmax layer of the neural network. 

\begin{equation} \label{eq:cat_example}
  cat:\ y_{mentor} = \{0.9,0.2,2 \times 10^{-6}\}
\end{equation}

Above is an example output with an input of cat image, 
the first item is obviously highest and the second item is relatively higher than the third.


In the target soften step, 
the output from complex mentor network \(\textbf y_{mentor}\) will soften in order to get the correlation between categories
by replacing the softmax function as below.

\begin{equation} \label{eq:new_soft_max}
  f(z_{(i)}) = \frac{exp(z^{(i)}/T)}{\sum_{j=0}^{N}exp(z^{(j)}/T)}\ for\ i=0,1,...,N
\end{equation}

There, \(T\) represents the "\emph{temperature}" of the soften procedure, a larger \(T\) leads to a more average result. 
If \(T =1\), the equation \ref{eq:cat_example} is the same with standard softmax function. 


\subsubsection{Distillation}

Distillation aims to transfer the knowledge from the more massive mentor neural network to the mentee. 
The mentee will use the output of the mentor with high temperature as the target labels.
Equally, the softmax layer of the mentee neural network has the same temperature with its mentor.

As a result, the cross-entropy between the mentee and mentor presents as:

\begin{equation} \label{eq:cost_function}
  C(y_{mentee}, y_{mentor}) = - \sum y_{mentor}log(y_{mentee})
\end{equation}

Insert equation \ref{eq:new_soft_max} into equation \ref{eq:cost_function}, we can derivate below:

\begin{equation} \label{eq:cost_function1}
  C(y_{mentee}, y_{mentor}) = - \sum_i f(v_i)log(f(z_i))
\end{equation}

There, \(v_i,\ z_i\) shows the input of mentor and mentee's softmax layer respectively.

Thus, the gradient of equation \ref{eq:cost_function1} is:

\begin{equation} \label{eq:gradient_cost}
  \frac{\nabla C}{\nabla z_i} = \frac{1}{T}(f(v_i) - f(z_i))
\end{equation}

Expand equation \ref{eq:gradient_cost}, while \(T\) is large enough, the equation transform into below:

\begin{equation} \label{eq:gradient_cost1}
  \frac{\nabla C}{\nabla z_i} \approx \frac{1}{T}( \frac{1+z_i/T}{N+\sum_j z_i/T} - \frac{1+v_i/T}{N+\sum_j v_i/T} ) = \frac{1}{T} (\frac{z_i - v_i}{N})
\end{equation}

Within the cost function \ref{eq:cost_function1} and the gradient equation \ref{eq:gradient_cost1}, 
the mentee neural network can learn the knowledge from its mentor.

The Dark Knowledge introduced an excellent approach to mobile training. 
A large and well-trained Neural Network, which has a general knowledge of a scenario, can be computed and stored in the powerful server cloud.
In the meantime, a small mentee network regularized by the mentor network can be saved and adjusted on the mobile devices.
For a specific use case, the mentee network can learn from that and adapt the predicted result. 



% Maybe I can move this part to another section
The advantage of this method is distinct, 
the size of mentee network is much smaller than the mentor network but has similar performance
with the complex mentor network. 


\subsection{Federal learning among multiple mobile devices}
\label{sub_sec:federal_learning}

Google also published \emph{Federal Learning} for solving the issue of training models on mobile devices.
Their approach tries to train a neural network in multiple mobile phones, each phone only trains a few iterations,
and the server will integrate all the tuned parameters of the neural network. 
This approach makes the training on the mobile devices possible.

In 2010, Zinkevich et al.\cite{Zinkevich2010} discovered a method of utilizing multiple machines to parallelize the gradient descent.
In their approach, the whole system comprises a server and several clients. 
The clients will only train one iteration with one batch of data by using Stochastic Gradient Descent(SGD) algorithm, 
then the server will combine all the calculated weight parameters and computes the average value of parameters.
This algorithm is called one-shot averaging because clients will only train one iteration with one batch.

One-shot averaging exists some issues, one of them is that in some case the performance will be worse than training
the model on one computer\cite{Shamir2013}. In addition, one-shot averaging costs a multitude of communication resources
due to the averaging step need to be performed every time after calculating the gradient.


To overcome those issue, the \emph{Federal Learning} mainly uses two methods: \emph{Federal Averaging} 
and shared initial weight.

\emph{Federal Averaging} is an optimization of one-shot averaging, the algorithm controls the distributed learning process by
three parameters: $C$ presents the fraction of clients that calculate gradient descent on each round; $B$ is the minibatch size
while client performs the computation; $E$ indicates the amount of training executed on each round.
On each round of \emph{Federal Averaging}, a number of $C$ clients will be randomly selected, performing $E$ times gradient
descent, and finally, return the updated weight parameters to the server node. As the clients will update the 
weight parameters several $E$ times before return the result to the server node, this method decreases the communication cost.
Figure \ref{alg:FederalAveragingAlgorithm} presents a pseudo-code of \emph{Federal Averaging}, all initial weight was shared already.


\begin{figure}[t!]
  \begin{center}
    % Note how the file extension has been removed from the filename below
    % so that the LaTeX command can automatically pick any supported file format
    \includegraphics[width=0.6\textwidth]{figures/Algorithm}
    \caption{Federal Averaging. The $K$ clients are indexed by $k$; $B$ is the local minibatch size, 
            $E$ is the number of local epochs, and $η$ is the learning rate.}
    \label{alg:FederalAveragingAlgorithm}
  \end{center}
\end{figure}


Sharing initial weights is an empirical method found by authors. They found that starting the models with the same random
value will lead to a proper optimization even though the models were trained independently with two different subsets of the data.
Figure \ref{fig:share_weight} shows the result of training the same MNIST dataset \cite{lecun2010mnist} without and within the 
shared initial weight methods. 
Within this approach, averaging the models have a considerably small loss over the training set.

\begin{figure}[t!]
  \begin{center}
    % Note how the file extension has been removed from the filename below
    % so that the LaTeX command can automatically pick any supported file format
    \includegraphics[width=0.7\textwidth]{figures/share_weight}
    \caption{The left independently initialize the weight; in the right case, the models were initialized by the same seed.}
    \label{fig:share_weight}
  \end{center}
\end{figure}

With the \emph{Federal Learning}, we are able to reduce the communication cost and distribute the computation resources into multiple,
without a significant loss.
This technique makes the training on the mobile device available, Google already tested the \emph{Federal Learning} with Google's keyboard
on Android devices\cite{BrendanMcMahanandDanielRamage2017}.

%------------------------------------------------------------

\subsection{Comparison}

Table \ref{table:comparing} shows the comparison between these two methods. 
As we discuss in section \ref{sec:characteristic_mobile_devices}, 
the for different mobile devices the requirement is separate, we will talk about it in this part.

For wearable devices, the most important concerns are intensive computational resources and battery. 
Because of these concerns, the complexity should be as simple as possible. 
The \emph{Knowledge Distillation} approach is good in these aspects, so we suggest it as a useful solution for 
implementing neural network training on wearable devices.

Vehicle devices have the most computation resources, so the complexity values less in this case.
But one of the critical requirement is the privacy protection and capability of sharing the results
of training. Based on these, \emph{Federal Learning} is a better choice.

In mobile phones, the limitation of power and computation is not considerably strict. 
Also, the privacy issue is also sensitive for mobile devices. Our suggestion is the combination
of these two approaches for achieving both requirements at the same time.



\begin{table}
  
\begin{center}
  \begin{tabular}{ |c|c|c| } 
   \hline
                                               & Knowledge Distillation & Federal Learning \\ 
   \hline
   Decreasing the complexity                   & yes                    & no \\ 
   \hline
   adaptability                                & not good               & good \\ 
   \hline
   Ad-hoc/distributed training                 & no                     & yes \\ 
   \hline
   Offline training                            & yes                    & no \\ 
   \hline
   Communication cost                          & no                     & yes \\ 
   \hline
   Accelerating one iteration                  & yes                    & no \\ 
   \hline
   Accuracy preservation                       & no                     & yes \\ 
   \hline
   Sharing the training                        & no                     & yes \\ 
   \hline
  \end{tabular}
\end{center}

  \caption{Comparison between \emph{Knowledge Distillation} and \emph{Federal Learning} from the mobile perspective.}
\label{table:comparing}
\end{table}


%============================================================


\section{Conclusion and Future Work}
\label{sec:conclusion}

This paper firstly introduces what Deep learning and the neural network is; shows the current situation on this technology;
lists the background and challenges on training Deep Neural Network. Additionally, two state-of-art approaches were 
presented as possible solutions of implementing training the neural network on mobile devices. \emph{Knowledge Distillation} 
is focusing on generating a smaller neural network which can run on the limited computational devices; 
\emph{Federal Learning} raises a solution that distributes the computational capability, makes the training process
extendable. 

The two approaches solving the challenges in a different way, which means they can integrate together. 
The combination of those will be an exciting goal for the future work. 

%TODO: add disadvantage of dark knowledge/knowledge Distillation
%TODO disadvantage of knowledge distillation
%   1. the performance is bad on small set of categories
%   2. not efficient on GAN neural network


%============================================================


\bibliographystyle{plain}
\bibliography{cs-seminar}

\end{document}
