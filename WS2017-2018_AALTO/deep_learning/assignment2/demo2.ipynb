{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration on Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Convolutional Neural Networks (CNN) are special, biologically inspired variants of Multi-Layer Perceptrons. They have proven to be effective in areas such as image recognition and classification. There are four main operations that are the basic building blocks of every Convolutional Neural Network:</p>\n",
    "<ol>\n",
    "<li>Convolution</li>\n",
    "<li>Non-Linearity</li>\n",
    "<li>Pooling or Down-sampling</li>\n",
    "<li>Classification or Fully Connected Layer</li>\n",
    "</ol>\n",
    "<p>In this demonstration we will walk you through creating a CNN with one convolution layer to recognise handwritten digits from the classic MNIST dataset. The architecture of the network that we will create is similar to the figure below (This figure will not be displayed when you export to .pdf).: </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/rgVIeVy.jpg\" alt=\"Demo Architecture\" title=\"Figure 1\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We will begin by first importing the necessary python libraries:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import six.moves.cPickle as pickle\n",
    "import gzip\n",
    "import os\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rd\n",
    "from theano.tensor.signal import pool\n",
    "from theano.tensor.nnet import conv2d\n",
    "%matplotlib inline\n",
    "print('***** Import complete *****')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Now we shall proceed to load the datasets into tensors. For this demo we will be using the MNIST dataset. Using the entire MNIST dataset would be computationally intensive and may take too much time. Hence, we shall draw a random sample from it with nearly equal representation of all the 10 digits for the training, validation and test sets. For the training and validation set, we take one-third the number of training set samples. Every image can be represented as a matrix of digits where each entry represents a pixel. In the MNIST dataset, the pixels are in grey scale and normalised. The images are of dimension 28 x 28 pixels and are flattened to an array of 784 elements. We load the dataset into the test, validation and training set tensors. If the corresponding pickle (.pkl) file is not present in the current directory, it will be downloaded for you. The dataset is partitioned into:</p>\n",
    "<ul>\n",
    "<li>50,000 training samples from which we draw 6000 samples.</li>\n",
    "<li>10,000 validation samples from which we draw 2000 samples.</li>\n",
    "<li>10,000 testing samples from which we draw 2000 samples.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'mnist.pkl.gz'\n",
    "data_dir, data_file = os.path.split(dataset)\n",
    "\n",
    "# Check if data file present\n",
    "if data_dir == \"\" and not os.path.isfile(dataset):\n",
    "    new_path = os.path.join('', dataset)\n",
    "    if os.path.isfile(new_path) or data_file == 'mnist.pkl.gz':\n",
    "        dataset = new_path\n",
    "\n",
    "# Download the file from MILA if not present \n",
    "if (not os.path.isfile(dataset)) and data_file == 'mnist.pkl.gz':\n",
    "    from six.moves import urllib\n",
    "    origin = (\n",
    "        'http://www.iro.umontreal.ca/~lisa/deep/data/mnist/mnist.pkl.gz'\n",
    "    )\n",
    "    print('Downloading data from %s' % origin)\n",
    "    urllib.request.urlretrieve(origin, dataset)\n",
    "\n",
    "print('***** Loading data *****')\n",
    "\n",
    "# Open the file\n",
    "with gzip.open(dataset, 'rb') as f:\n",
    "    try:\n",
    "        train_set, valid_set, test_set = pickle.load(f, encoding='latin1')\n",
    "    except:\n",
    "        train_set, valid_set, test_set = pickle.load(f)\n",
    "\n",
    "# Sub-sample and store in a tensor\n",
    "def shared_dataset(data_xy, sample_size=6000, borrow=True):\n",
    "    data_x, data_y = data_xy\n",
    "    indices = 0\n",
    "    if (sample_size < 0):\n",
    "        print('Sample size too small!')\n",
    "        return\n",
    "    try:\n",
    "        indices = rd.sample(range(0, data_y.shape[0]), sample_size)\n",
    "    except ValueError:\n",
    "        print('Sample size exceeds data size.')\n",
    "    data_x = data_x[indices, :]\n",
    "    data_y = data_y[indices]\n",
    "\n",
    "    shared_x = theano.shared(np.asarray(data_x,\n",
    "                                        dtype=theano.config.floatX),\n",
    "                             borrow=borrow)\n",
    "    shared_y = theano.shared(np.asarray(data_y,\n",
    "                                        dtype=theano.config.floatX),\n",
    "                             borrow=borrow)\n",
    "    return shared_x, T.cast(shared_y, 'int32'), (data_x, data_y)\n",
    "\n",
    "# Default training sample size = 6000 samples\n",
    "# Max size = 50000\n",
    "train_size = 6000\n",
    "test_set_x, test_set_y, test_set = shared_dataset(\n",
    "                                                  test_set,\n",
    "                                                  sample_size=train_size//3\n",
    "                                                 )\n",
    "valid_set_x, valid_set_y, valid_set = shared_dataset(\n",
    "                                                     valid_set,\n",
    "                                                     sample_size=train_size//3\n",
    "                                                    )\n",
    "train_set_x, train_set_y, train_set = shared_dataset(\n",
    "                                                     train_set,\n",
    "                                                     sample_size=train_size\n",
    "                                                     )\n",
    "# Training set dimension: 6000 x 784\n",
    "print('Training set: %d samples'\n",
    "      %(train_set_x.get_value(borrow=True).shape[0])) \n",
    "# Test set dimension: 2000 x 784\n",
    "print('Test set: %d samples'\n",
    "      %(test_set_x.get_value(borrow=True).shape[0]))\n",
    "# Validation set dimension: 2000 x 784\n",
    "print('Validation set: %d samples'\n",
    "      %(valid_set_x.get_value(borrow=True).shape[0]))\n",
    "print('The training set looks like this: ')\n",
    "print(train_set[0])\n",
    "print('The labels looks like this:')\n",
    "print(train_set[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Now, we shall visualise a random training sample. When plotting, we scale the intensity to the range from 0 to 255. The image is of 28 x 28 pixels.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a random image\n",
    "image_plot = rd.randint(0, len(train_set[1]))\n",
    "# Scaling image to [0, 255]\n",
    "pixels = np.array(train_set[0][image_plot] * 255, dtype='uint8')\n",
    "pixels = pixels.reshape((28, 28))\n",
    "label = train_set[1][image_plot]\n",
    "plt.title('Label: {label}'.format(label=label))\n",
    "plt.imshow(pixels, cmap='gray', interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Next we shall create the convolution layer as in the figure above. The primary purpose of the convolution layer is to extract features from the image. Convolution preserves the spatial relationship between pixels by learning image features using small squares of input data (in this case 5 x 5 pixels of data). In the convolution layer, each of the filters are slid over the image by 1 pixel (stride = 1). For every position, we compute element-wise multiplication between the filter and the sub-image under it and add the multiplication outputs to get the final integer which forms a single element of the output matrix. A non-linearity is introduced after every convolution operation. We then perform pooling which is discussed later. This non-linearity helps our convolutional neural network to model data which is non-linear in nature. In this demonstration, we use the non-linear, tanh function. To summarise, our convolutional layer will have the following specifications: </p>\n",
    "<ul>\n",
    "<li>9 filters or channels </li>\n",
    "<li>Each filter will have a 5 x 5 \"field of view\"</li>\n",
    "<li>The stride will be of 1.</li>\n",
    "<li>It will perform 2 x 2 Max Pooling. We will define the pooling function later.</li>\n",
    "<li>It will use a Tanh non-linearity</li>\n",
    "<li>The function shall return the outputs from the non-linearised outputs as well as the parameters (weights and biases).\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convLayer(rng, data_input, filter_spec, image_spec, pool_size, activation):\n",
    "    # Function that defines the convolution layer. Calls the \n",
    "    # activation function and then Pooling function.\n",
    "    \n",
    "    # Inputs:\n",
    "    # rng - random number generator used to initialize weights.\n",
    "    # data_input - symbolic input image tensor.\n",
    "    # filter_spec - dimensions of filter in convolution layer.\n",
    "    #               tuple format:(# of channels, depth, height, width)\n",
    "    # image_spec - specifications of input images.\n",
    "    #              tuple format:(batch size, color channels, height, width)\n",
    "    # pool_size - specification of downsampling (pooling) factor.\n",
    "    #             tuple format: (# of rows, # of columns)\n",
    "    # activation - activation function to be used.\n",
    "    \n",
    "    # Outputs:\n",
    "    # output - tensor containing activations fed into next layer.\n",
    "    # params - list containing layer parameters\n",
    "    \n",
    "    # Creating a shared variable for weights that are initialised with samples\n",
    "    # drawn from a gaussian distribution with 0 mean and standard deviation of \n",
    "    # 0.1. This is just a random initialisation.\n",
    "    W = theano.shared(\n",
    "        np.asarray(rng.normal(loc=0, scale=0.1, size=filter_spec)),\n",
    "        borrow=True)\n",
    "    \n",
    "    # Bias is a 1 D tensor -- one bias per output feature map. \n",
    "    # Initialised with zeros.\n",
    "    b = theano.shared(np.zeros((filter_spec[0],)), borrow=True)\n",
    "    \n",
    "    # Convolve input with specifications. This is Theano's convolution\n",
    "    # function. It takes as input the data tensor, filter weights, filter \n",
    "    # specifications and the image specifications. In our example, the\n",
    "    # dimensions of the output of this operation would be:\n",
    "    # mini_batch_size x 9 x 24 x 24\n",
    "    conv_op_out = conv2d(\n",
    "        input=data_input,\n",
    "        filters=W,\n",
    "        filter_shape=filter_spec,\n",
    "        input_shape=image_spec)\n",
    "    \n",
    "    # Add the bias term and use the specified activation function/ \n",
    "    # non-linearity.\n",
    "    # b.dimshuffle returns a view of the bias tensor with permuted dimensions.\n",
    "    # In this case our bias tensor is originally of the dimension 9 x 1. The\n",
    "    # dimshuffle operation used below, broadcasts this into a tensor of\n",
    "    # 1 x 9 x 1 x 1. Note that there is one bias per output feature map.\n",
    "    layer_activation = activation(conv_op_out + b.dimshuffle('x', 0, 'x', 'x'))\n",
    "    \n",
    "    # Perform pooling on the activations. It is required to reduce the spatial\n",
    "    # size of the representation to reduce the number of parameters and\n",
    "    # computation in the network. Hence, it helps to control overfitting\n",
    "    # Output dimensions: (# channels, image height-filter height+1, \n",
    "    #                     image width - filter width+1)\n",
    "    # In our demo, the dimensions would be of mini_batch_size x 9 x 12 x 12\n",
    "    output = pooling(input_pool=layer_activation, size=pool_size)\n",
    "    \n",
    "    # Combine the weights and biases into a single list\n",
    "    params = [W, b]\n",
    "    return output, params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Pooling or down-sampling reduces the dimensionality of each of the feature maps (outputs of the filters) while retaining the most important information. We will perform 2 x 2 Max Pooling. This involves taking the largest element in a 2 x 2 window from the feature maps. Pooling is useful as it helps to reduce the computation load by reducing the number of parameters that need to be optimised/learnt while making the network invariant to small transformations and distortions. The pooling function will be called by the <b>convLayer</b> function.<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pooling(input_pool, size):\n",
    "    # Function to perform Max-Pooling on each feature map\n",
    "    \n",
    "    # Inputs:\n",
    "    # input_pool - feature maps obtained as output from convolution layer.\n",
    "    # size - specification of downsampling (pooling) factor.\n",
    "    #        tuple format: (# of rows, # of columns)\n",
    "    \n",
    "    # Outputs:\n",
    "    # pool_out - pooled output.\n",
    "    #            dimensions: (# of channels, conv_output_height/#rows,\n",
    "    #                         conv_output_width/#rows)\n",
    "    \n",
    "    pool_out = pool.pool_2d(input=input_pool, ws=size, ignore_border=True)\n",
    "    return pool_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Now we shall construct the fully-connected layer. This is modelled on a traditional perceptron and we shall perform the softmax operation for the activations. Every neuron in this layer is connected to every output from the pooling operation. The purpose of this layer is to use the identified features for classifying the input image into various classes (in our case labels from 0-9) based on the training dataset. After the single fully-connected layer, the final predictions are made using the softmax function. This is where the final classification takes place. The sum of the output probabilities is 1. This is ensured by using Softmax as the activation function. The Softmax function takes a vector of arbitrary real values and reduces it to a vector of numbers from 0 to 1 that sum to 1. This function shall return the predicted probabilities for each class, the final prediction (prediction of class whose probability is maximum) and the parameters (W, b)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fullyConnectedLayer(data_input, num_in, num_out):\n",
    "    # Function to create the fully-connected layer and makes use of the\n",
    "    # output from the previous layer. It is the final layer in the\n",
    "    # convolutional neural network architecture and comprises of the\n",
    "    # Softmax activations.\n",
    "    \n",
    "    # Inputs:\n",
    "    # data_input - input for the softmax layer.\n",
    "    #              Symbolic tensor of dimensions:\n",
    "    #              (mini_batch_size, # channels * 12 * 12) \n",
    "    # num_in - number of input units. Dimensions would be:\n",
    "    #           (# channels * 12 * 12)\n",
    "    # num_out - number of output units or number of output labels.\n",
    "    \n",
    "    # Outputs:\n",
    "    # p_y_given_x - class-membership probabilities.\n",
    "    # y_pred - class with maximal probability\n",
    "    # params - parameters of the layer\n",
    "    \n",
    "    # Creating a shared variable for weights that are initialised with samples\n",
    "    # drawn from a gaussian distribution with 0 mean and standard deviation of \n",
    "    # 0.1. This is just a random initialisation.\n",
    "    W = theano.shared(\n",
    "        value=np.asarray(\n",
    "            rng.normal(loc=0, scale=0.1, size=(num_in, num_out))),\n",
    "        name='W',\n",
    "        borrow=True)\n",
    "                   \n",
    "    # Creating a shared variable for biases that are initialised with\n",
    "    # zeros.\n",
    "    b = theano.shared(\n",
    "        value=np.zeros((num_out,)),\n",
    "        name='b',\n",
    "        borrow=True)\n",
    "    \n",
    "    # Compute class-membership probabilities using the Softmax activation\n",
    "    # function.\n",
    "    p_y_given_x = T.nnet.softmax(T.dot(data_input, W) + b)\n",
    "    \n",
    "    # Class prediction. Find class whose probability is maximal.\n",
    "    y_pred = T.argmax(p_y_given_x, axis=1)\n",
    "                   \n",
    "    # Combine weights and biases into a single list.\n",
    "    params = [W, b]\n",
    "    return p_y_given_x, y_pred, params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Now that we have the basic building blocks in place, we focus on learning all the weights in the network. This is done with the help of back-propogation. Our objective is to learn the parameters in such a way that we minimise the total cost. The parameters are updated using Stochastic Gradient Descent so that the error with the new parameters will be lower. The cost that we will minimise is the negative conditional log likelihood, given by: </p> $$ \\frac{1}{|\\mathcal{D}|} \\mathcal{L} (\\theta=\\{W,b\\}, \\mathcal{D}) =\n",
    "            \\frac{1}{|\\mathcal{D}|} \\sum_{i=0}^{|\\mathcal{D}|}\n",
    "                \\log(P(Y=y^{(i)}|x^{(i)}, W,b)) $$\n",
    "           $$ \\ell (\\theta=\\{W,b\\}, \\mathcal{D}) = -\\mathcal{L}(\\theta=\\{W, b\\}, \\mathcal{D})$$\n",
    "<p>Our objective is to learn the parameter values that minimise this cost. Parameters like number of filters, filter sizes, architecture of the network etc; have been fixed beforehand and will not change during the training process.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def negative_log_lik(y, p_y_given_x):\n",
    "    # Function to compute the cost that is to be minimised. \n",
    "    # Here, we compute the negative log-likelihood.\n",
    "    \n",
    "    # Inputs:\n",
    "    # y - expected class label\n",
    "    # p_y_given_x - class-membership probabilities\n",
    "    \n",
    "    # Outputs:\n",
    "    # cost_log - the computed negative log-lik cost\n",
    "    \n",
    "    # Generate the relevant row indices\n",
    "    rows = T.arange(y.shape[0])\n",
    "    \n",
    "    # Generate the relevant column indices\n",
    "    cols = y;\n",
    "    \n",
    "    # Computing the log probabilities\n",
    "    log_prob = T.log(p_y_given_x)\n",
    "    \n",
    "    # Obtain the mean of the relevant entries. Loss is formally\n",
    "    # defined over the sum of the individual error terms as in\n",
    "    # the eqquation above. However, we use mean instead to speed\n",
    "    # up convergence.\n",
    "    cost_log = -T.mean(log_prob[rows, cols])\n",
    "    return cost_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We also need a function to compute the number of errors (i.e. wrongly classified instances). We shall return the fraction of wrongly classified instances.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def errors(y, y_pred):\n",
    "    # Function to compute the fraction of wrongly classified\n",
    "    # instances.\n",
    "    \n",
    "    # Inputs:\n",
    "    # y - expected class label\n",
    "    # y_pred - predicted class label\n",
    "    \n",
    "    # Outputs:\n",
    "    # count_error - number of wrongly classified instances\n",
    "    \n",
    "    # Counting the number of number of wrong predictions. T.neq\n",
    "    # function returns 1 if the variables compared are not equal.\n",
    "    # The mean would return the fraction of mismatches.\n",
    "    count_error = T.mean(T.neq(y_pred, y))\n",
    "    return count_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We can begin to put it all together by first defining some hyper-parameters. The learning rate is a part of the Stochastic Descent algorithm and dictates how much an update would effect the value of the paramaters. If too small learning rates are passed, the algorithm will take a long time to converge on the optimal values. If the learning rate is too large, the algorithm may keep missing the optimal values. The number of epochs is the number of times the entire training data will be iterated over. Also, the mini-batch size is the number of data samples in a mini-batch. We split the training data into smaller 'batches'. These are known as mini-batches and in each iteration of training, we use one mini-batch. There will be more details on mini-batches later in this course. For now, it suffices to know that mini-batches are smaller samples of the training data such that each iteration uses one mini-batch.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set learning rate used for Stochastic Gradient Descent\n",
    "learning_rate = 0.1\n",
    "# set number of training epochs\n",
    "num_epochs = 10\n",
    "# set number of kernels for each convolution layer\n",
    "# for e.g. 2 layers - [20, 50]. layer1 = 20, layer2 = 50\n",
    "num_filters = [9]\n",
    "# set mini-batch size to be used\n",
    "mini_batch_size = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>For better performance, we the data into mini-batches. For this example, we use a mini-batch size of 50 samples.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeding the random number generator\n",
    "rng = np.random.RandomState(23455)\n",
    "\n",
    "# Computing number of mini-batches\n",
    "n_train_batches = train_set_x.get_value(borrow=True).shape[0]\n",
    "n_valid_batches = valid_set_x.get_value(borrow=True).shape[0]\n",
    "n_test_batches = test_set_x.get_value(borrow=True).shape[0]\n",
    "n_train_batches //= mini_batch_size\n",
    "n_valid_batches //= mini_batch_size\n",
    "n_test_batches //= mini_batch_size\n",
    "\n",
    "print('train: %d batches, test: %d batches, validation: %d batches'\n",
    "      % (n_train_batches, n_test_batches, n_valid_batches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We can now create a Theano Computation Graph. The following steps create a computation graph for training, validation and testing. In the convolution layer, filtering reduces the image size to (28-5+1) x (28-5+1) = 24 x 24. Maxpooling reduces this further to (24/2) x (24/2) = 12 x 12. Hence, the 4D output tensor from the convolution layer is of shape (mini_batch_size, num_filters[0], 12, 12). This is fed into hidden layer which produces a matrix of (mini_batch_size, num_filters[0] \\* 12 \\* 12) = (mini_batch_size, 1296). This is then fed into the Softmax layer which produces the probabilities of the 10 classes for each training sample in the batch.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mini-batch index\n",
    "mb_index = T.lscalar()\n",
    "# rasterised images\n",
    "x = T.matrix('x')\n",
    "# image labels\n",
    "y = T.ivector('y')\n",
    "\n",
    "print('***** Constructing model ***** ')\n",
    "\n",
    "# Reshaping matrix of mini_batch_size set of images into a \n",
    "# 4-D tensor of dimensions: mini_batch_size x 1 x 28 x 28\n",
    "layer0_input = x.reshape((mini_batch_size, 1, 28, 28))\n",
    "\n",
    "# First convolution and pooling layer\n",
    "# 4D output tensor is of shape:\n",
    "# mini_batch_size x 9 x 12 x 12\n",
    "[layer0_output, layer0_params] = convLayer(\n",
    "    rng,\n",
    "    data_input=layer0_input,\n",
    "    image_spec=(mini_batch_size, 1, 28, 28),\n",
    "    filter_spec=(num_filters[0], 1, 5, 5),\n",
    "    pool_size=(2, 2),\n",
    "    activation=T.tanh)\n",
    "\n",
    "# Flatten the output into dimensions:\n",
    "# mini_batch_size x 1296\n",
    "fc_layer_input = layer0_output.flatten(2)\n",
    "\n",
    "# The fully connected layer operates on a matrix of \n",
    "# dimensions: mini_batch_size x 1296\n",
    "# It clasifies the values using the softmax function.\n",
    "[p_y_given_x, y_pred, fc_layer_params] = fullyConnectedLayer(\n",
    "    data_input=fc_layer_input,\n",
    "    num_in=num_filters[0]*12*12,\n",
    "    num_out=10)\n",
    "\n",
    "# Cost that is minimised during stochastic descent. \n",
    "cost = negative_log_lik(y=y, p_y_given_x=p_y_given_x)\n",
    "\n",
    "# Creates a Theano function that computes the mistakes on the validation set.\n",
    "# This performs validation.\n",
    "\n",
    "# Note: the givens parameter allows us to separate the description of the\n",
    "# Theano model from the exact definition of the inputs variable. The 'key'\n",
    "# that is passed to the graph is subsituted with the data from the givens\n",
    "# parameter. In this demo we built the model with a regular Theano tensor\n",
    "# and we use givens to speed up the GPU. We swap the input index with a \n",
    "# slice corresponding to the mini-batch of the dataset to use.\n",
    "\n",
    "# mb_index is the mini_batch_index\n",
    "valid_model = theano.function(\n",
    "    [mb_index],\n",
    "    errors(y, y_pred),\n",
    "    givens={\n",
    "        x: valid_set_x[\n",
    "            mb_index * mini_batch_size:\n",
    "            (mb_index + 1) * mini_batch_size\n",
    "            ],\n",
    "        y: valid_set_y[\n",
    "            mb_index * mini_batch_size:\n",
    "            (mb_index + 1) * mini_batch_size\n",
    "            ]})\n",
    "\n",
    "# Create a Theano function that computes the mistakes on the test set.\n",
    "# This evaluated our model's accuracy.\n",
    "test_model = theano.function(\n",
    "    [mb_index],\n",
    "    errors(y, y_pred),\n",
    "    givens={\n",
    "        x: test_set_x[\n",
    "            mb_index * mini_batch_size:\n",
    "            (mb_index + 1) * mini_batch_size\n",
    "            ],\n",
    "        y: test_set_y[\n",
    "            mb_index * mini_batch_size:\n",
    "            (mb_index + 1) * mini_batch_size\n",
    "            ]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We create a list of all model parameters to be fit by gradient descent and compute the gradients.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List of parameters to be fit during training\n",
    "params = fc_layer_params + layer0_params\n",
    "# Creates a list of gradients\n",
    "grads = T.grad(cost, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Below, train_model is a function that updates the model parameters by Stochastic Gradient Descent. We create the updates list by looping over all ( params[i], grads[i] ) pairs. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creates a function that updates the model parameters by SGD.\n",
    "# The updates list is created by looping over all \n",
    "# (params[i], grads[i]) pairs.\n",
    "updates = [(param_i, param_i - learning_rate * grad_i)\n",
    "           for param_i, grad_i in zip(params, grads)]\n",
    "\n",
    "# Create a Theano function to train our convolutional neural network.\n",
    "train_model = theano.function(\n",
    "    [mb_index],\n",
    "    cost,\n",
    "    updates=updates,\n",
    "    givens={\n",
    "        x: train_set_x[\n",
    "            mb_index * mini_batch_size:\n",
    "            (mb_index + 1) * mini_batch_size\n",
    "            ],\n",
    "        y: train_set_y[\n",
    "            mb_index * mini_batch_size:\n",
    "            (mb_index + 1) * mini_batch_size\n",
    "            ]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Before we can begin training our model, we need to define some helper functions to help with plotting the cost after each iteration as well as the accuracy and state of the filters after each epoch. We shall plot the filter weights. The weights are useful to visualize because well-trained networks usually display nice and smooth filters without any noisy patterns. Noisy patterns can be an indicator of a network that has not been trained for long enough, or possibly a too low regularization strength that may have led to overfitting. We display the plots during the model training phase and you can observe as they change with each iteration/epoch.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some code to help with the plotting. \n",
    "# You don't need to go through the plotting \n",
    "# code in detail.\n",
    "\n",
    "#### Code for the Visualisations #### \n",
    "%matplotlib notebook\n",
    "def update_weight(weights, ax_wt, fig_wt, epoch):\n",
    "    # global normalise\n",
    "    weights = np.array(weights[:,0])\n",
    "    min_channel = np.min(weights)\n",
    "    max_channel = np.max(weights)\n",
    "    a = 255/(max_channel - min_channel)\n",
    "    b = 255 - a * max_channel\n",
    "    weights = a * weights + b\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            idx = 3 * i + j;\n",
    "            channel = weights[idx]\n",
    "            ax_wt[i, j].set_xticklabels([])\n",
    "            ax_wt[i, j].set_yticklabels([])\n",
    "            ax_wt[i, j].set_xticks([])\n",
    "            ax_wt[i, j].set_yticks([])\n",
    "            im = ax_wt[i, j].imshow(channel,\n",
    "                                    cmap='gray',\n",
    "                                    interpolation='None') \n",
    "    fig_wt.suptitle(\n",
    "        'Visualisation of Filters After %d Epoch(s)' %epoch, y=1)\n",
    "    fig_wt.subplots_adjust(right=0.8)\n",
    "    cbar_ax = fig_wt.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "    ch_max = int(np.max(channel))\n",
    "    ch_min = int(np.min(channel))\n",
    "    ch_mid = int(ch_min + (ch_max - ch_min)/2)\n",
    "    cbar = fig_wt.colorbar(im, cax=cbar_ax, ticks=[ch_min+2, ch_mid, ch_max-2])\n",
    "    cbar.ax.set_yticklabels([\"{:.3f}\".format(min_channel),\n",
    "                             \"{:.3f}\".format(min_channel+\n",
    "                                             (max_channel-min_channel)/2),\n",
    "                             \"{:.3f}\".format(max_channel)])\n",
    "    fig_wt.canvas.draw()\n",
    "            \n",
    "def update_line(line1, fig, x, y):\n",
    "    line1.set_xdata(np.append(line1.get_xdata(), x))\n",
    "    line1.set_ydata(np.append(line1.get_ydata(), y))\n",
    "    fig.canvas.draw()\n",
    "\n",
    "def update_cost_plot(line2, fig, x, y):\n",
    "    line2.set_xdata(np.append(line2.get_xdata(), x))\n",
    "    line2.set_ydata(np.append(line2.get_ydata(), y))\n",
    "    fig.canvas.draw() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We can now begin training the model. In this example, we go over the training set 10 times (10 epochs). From the plots we can see that as training progresses, the cost and prediction error decreases. The cost seems to oscillate about a fixed value. Also, we can also notice that the randomness in the filter weights decreases during the training process. This in a way shows our model improving its knowledge on the dataset. <b>Note: Training can take a while. Be patient!</b> </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "iter = 0\n",
    "epoch = 0\n",
    "cost_ij = 0\n",
    "valid_losses = [valid_model(i) for i in range(n_valid_batches)]\n",
    "valid_score = np.mean(valid_losses)\n",
    "plt.ion()\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "ax = fig.add_subplot(211)\n",
    "line1, = ax.plot(epoch, valid_score, 'b-')\n",
    "ax.set_xlim(0, num_epochs)\n",
    "ax.set_ylim(0, 1.1)\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Prediction Error')\n",
    "ax.set_title('Prediction Error vs. Number of Epochs')\n",
    "\n",
    "ax2 = fig.add_subplot(212)\n",
    "line2, = ax2.plot(iter, cost_ij, 'r-')\n",
    "ax2.set_xlabel('Iterations')\n",
    "ax2.set_ylabel('Cost')\n",
    "ax2.set_title('Cost vs. Iterations')\n",
    "ax2.set_xlim(0, num_epochs * n_train_batches)\n",
    "ax2.set_ylim(0, 4)\n",
    "plt.tight_layout()\n",
    "fig.show()\n",
    "\n",
    "fig_wt, ax_wt = plt.subplots(3, 3, sharex='col', sharey='row',\n",
    "                            gridspec_kw=dict(wspace=0.02,\n",
    "                                             hspace=0.02, \n",
    "                                             top=0.95,\n",
    "                                             bottom=0.05,\n",
    "                                             left=0.17,\n",
    "                                             right=0.845))\n",
    "\n",
    "fig_wt.show()\n",
    "plots_conv = layer0_params[0].get_value()\n",
    "plots_fc = fc_layer_params[0].get_value()\n",
    "update_weight(plots_conv, ax_wt, fig_wt, epoch)\n",
    "plots_conv = np.array(plots_conv[:, 0])\n",
    "biases_fc = fc_layer_params[1].get_value()\n",
    "\n",
    "# Create buffer arrays for the channel and fully connected\n",
    "# layer weights. These are for visualisation only and are\n",
    "# chosen arbitrarily!\n",
    "plot_arr1 = np.array([plots_conv[:, 1, 1]]);\n",
    "plot_arr2 = np.array([plots_conv[:, 2, 2]]);\n",
    "plot_arr3 = np.array([plots_conv[:, 3, 3]])\n",
    "plot_fc1 = np.array([plots_fc[1, 1]])\n",
    "plot_fc2 = np.array([plots_fc[2, 2]])\n",
    "plot_fc3 = np.array([plots_fc[3, 3]])\n",
    "\n",
    "# Create a buffer array for the biases. These are for \n",
    "# visualisation only!\n",
    "plot_biases_arr = np.array([np.transpose(layer0_params[1].get_value())])\n",
    "plot_biases_fc_arr = np.array([np.transpose(biases_fc[0:5])])\n",
    "\n",
    "#### End of Visualisations Code ####\n",
    "\n",
    "# This is where we call the previously defined Theano functions. \n",
    "print('***** Training model *****')\n",
    "while (epoch < num_epochs):\n",
    "    epoch = epoch + 1\n",
    "    for minibatch_index in range(n_train_batches):\n",
    "        # Compute number of iterations performed or total number\n",
    "        # of mini-batches executed.\n",
    "        iter = (epoch - 1) * n_train_batches + minibatch_index\n",
    "        \n",
    "        # Perform the training of our convolution neural network.\n",
    "        # Obtain the cost of each minibatch specified using the \n",
    "        # minibatch_index.\n",
    "        cost_ij = train_model(minibatch_index)\n",
    "        \n",
    "        # Update the visualisation.\n",
    "        update_cost_plot(line2, fig, iter, cost_ij)\n",
    "        \n",
    "        # Obtain the weights for visualisation\n",
    "        plots_conv = layer0_params[0].get_value()\n",
    "        plots_fc_wt = fc_layer_params[0].get_value()\n",
    "        biases_fc = fc_layer_params[1].get_value()\n",
    "        plots_wt = np.array(plots_conv[:, 0])\n",
    "        \n",
    "        # Append weights to the buffer arrays for visualisation\n",
    "        plot_arr1 = np.append(plot_arr1, [plots_wt[:, 1, 1]], axis=0)\n",
    "        plot_arr2 = np.append(plot_arr2, [plots_wt[:, 2, 2]], axis=0)\n",
    "        plot_arr3 = np.append(plot_arr3, [plots_wt[:, 3, 3]], axis=0)\n",
    "        plot_fc1 = np.append(plot_fc1, [plots_fc_wt[1, 1]], axis=0)\n",
    "        plot_fc2 = np.append(plot_fc2, [plots_fc_wt[2, 2]], axis=0)\n",
    "        plot_fc3 = np.append(plot_fc3, [plots_fc_wt[3, 3]], axis=0)\n",
    "        plot_biases_arr = np.append(\n",
    "                               plot_biases_arr,\n",
    "                               [np.transpose(layer0_params[1].get_value())],\n",
    "                               axis=0)\n",
    "        plot_biases_fc_arr = np.append(\n",
    "                                  plot_biases_fc_arr,\n",
    "                                  [np.transpose(biases_fc[0:5])],\n",
    "                                  axis = 0)\n",
    "    \n",
    "    # Obtain the weights of the first convolutional layer.\n",
    "    conv_weights = layer0_params[0].get_value()\n",
    "    \n",
    "    # Update the visualisation\n",
    "    update_weight(conv_weights, ax_wt, fig_wt, epoch)\n",
    "    \n",
    "    # Compute the prediction error on each validation mini-batch by\n",
    "    # calling the previously defined Theano function for validation.\n",
    "    valid_losses = [valid_model(i) for i in range(n_valid_batches)]\n",
    "    \n",
    "    # Compute the mean prediction error across all the mini-batches.\n",
    "    valid_score = np.mean(valid_losses)\n",
    "    \n",
    "    # Update the visualisation.\n",
    "    update_line(line1, fig, epoch, valid_score)\n",
    "        \n",
    "print('***** Training Complete *****')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Let's visualise how the values of three weights in a channel change with iterations. We can observe that each of the weights converge to a value after some iterations. We will also visualise the evolution of the biases of each of the channels.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.ioff()\n",
    "fig_tr, axarr = plt.subplots(9,figsize=(8, 10), sharex=True)\n",
    "for ch_count in range(9):\n",
    "    l1 = axarr[ch_count].plot(plot_arr1[:, ch_count])\n",
    "    l2 = axarr[ch_count].plot(plot_arr2[:, ch_count])\n",
    "    l3 = axarr[ch_count].plot(plot_arr3[:, ch_count])\n",
    "    axarr[ch_count].yaxis.set_label_position(\"right\")\n",
    "    axarr[ch_count].set_ylabel('Channel '+str(ch_count+1))\n",
    "    \n",
    "axarr[0].set_title('Evolution of Three Arbitrary Weights in the 9 Channels')\n",
    "axarr[8].set_xlabel('Iterations')\n",
    "\n",
    "fig_tr.subplots_adjust(hspace=0.1)\n",
    "\n",
    "fig_bias, axarr_bias = plt.subplots(9,figsize=(8, 10), sharex=True)\n",
    "for ch_count in range(9):\n",
    "    axarr_bias[ch_count].plot(plot_biases_arr[:, ch_count], 'm-')\n",
    "    axarr_bias[ch_count].yaxis.set_label_position(\"right\")\n",
    "    axarr_bias[ch_count].set_ylabel('Channel '+str(ch_count+1))\n",
    "axarr_bias[0].set_title('Evolution of Biases')\n",
    "axarr_bias[8].set_xlabel('Iterations')\n",
    "fig_bias.subplots_adjust(hspace=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Also, let's visualise some weights and biases from the fully-connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "fig.suptitle('Evolution of Arbitrary Weights and Biases'\n",
    "             ' in the Fully-Connected Layer')\n",
    "ax = fig.add_subplot(211)\n",
    "ax.plot(plot_fc1)\n",
    "ax.plot(plot_fc2)\n",
    "ax.plot(plot_fc3)\n",
    "ax.set_ylabel('Weight Value')\n",
    "\n",
    "ax2 = fig.add_subplot(212)\n",
    "for i in range(5):\n",
    "    ax2.plot(plot_biases_fc_arr[:, i])\n",
    "ax2.set_ylabel('Bias value')\n",
    "ax2.set_xlabel('Iterations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>After the training is complete, we can evaluate the prediction accuracy of the trained Convolutional Neural Network over the unseen training set. This will give us a measure of how our trained model will perform on new unseen data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute prediction errors on the test set for each mini-batch by\n",
    "# calling the previous defined Theano function for evaluating our\n",
    "# model's performance.\n",
    "test_losses = [test_model(i) for i in range(n_test_batches)]\n",
    "\n",
    "# Compute the mean prediction error across all the mini-batches.\n",
    "test_score = np.mean(test_losses)\n",
    "print('Prediction error: %f %%' % (test_score * 100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The operations performed in the convolution layer are analogous to passing the image through several different filters. Different forms of the original image are obtained simply by changing the values in these filters (or more formally kernels). It is important to note that the convolution operation captures the local dependencies in the original image. The CNN learns the values of these filters on its own during the training process. The larger the number of filters we have, the more image features get extracted and the better our network becomes at recognizing patterns in unseen images. To make this clear, we shall take a random image from the test dataset and compare it to the outputs of the convolution layer. We have 9 filters in our convolution layer, hence there will be 9 different images. Notice below how the different filters generate different feature maps from the same original image. Also, note that the size of the image after the convolution layer is smaller as we have performed pooling/down-sampling</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for visualising the activations of the convolution\n",
    "# layer for a random input number. The objective of this \n",
    "# section is to give you an idea of what happens when\n",
    "# our network reads a new digit to classify. We will \n",
    "# visualise the outputs from each filter and the combined\n",
    "# prediction probabilities. Observe the plots carefully!\n",
    "\n",
    "# Note: the code below is similar to that discussed above.\n",
    "# However, a detailed understanding of this section is not\n",
    "# required. \n",
    "%matplotlib inline\n",
    "plt.ioff()\n",
    "# Choose a random image\n",
    "image_plot = rd.randint(0, (train_size//3)-mini_batch_size)\n",
    "# Create function to compute class-membership\n",
    "# prediction probabilites.\n",
    "f2 = theano.function([], p_y_given_x, givens={\n",
    "        x: test_set_x[image_plot:image_plot+mini_batch_size]})\n",
    "\n",
    "predictions = f2()\n",
    "pred_image = predictions[0] * 100\n",
    "\n",
    "# Parameters for bar chart of probabilities\n",
    "N = len(pred_image)\n",
    "x_axis = range(N)\n",
    "width = 1/1.5\n",
    "\n",
    "# Obtain convolution layer activations for sample\n",
    "W_new = layer0_params[0].get_value()\n",
    "b_new = layer0_params[1].get_value()\n",
    "x_new = T.matrix('x')\n",
    "inp_new = x.reshape((1, 1, 28, 28))\n",
    "\n",
    "# Perform convolution operation\n",
    "conv_op_out = conv2d(\n",
    "       input=inp_new,\n",
    "       filters=W_new,\n",
    "       filter_shape=(num_filters[0], 1, 5, 5),\n",
    "       input_shape=(1, 1, 28, 28))\n",
    "\n",
    "# Pool the output\n",
    "pooled_out = pooling(input_pool=conv_op_out,\n",
    "                     size=(2,2))\n",
    "\n",
    "# Obtain activations\n",
    "output = T.tanh(pooled_out)\n",
    "\n",
    "# Create function to obtain activations of conv layer\n",
    "f = theano.function([], output, givens={\n",
    "       x: test_set_x[image_plot:image_plot+1]})\n",
    "test = f()\n",
    "\n",
    "# Plotting code for sample, prediction probabilties and\n",
    "# convolution layer activations\n",
    "fig_actual = plt.figure(figsize=(8, 8))\n",
    "ax_actual = fig_actual.add_subplot(121)\n",
    "fig_actual.subplots_adjust(wspace=2)\n",
    "pixels = np.array(test_set[0][image_plot] * 255,\n",
    "                     dtype='uint8')\n",
    "pixels = pixels.reshape((28, 28))\n",
    "label = test_set[1][image_plot]\n",
    "ax_actual.set_xticklabels([])\n",
    "ax_actual.set_yticklabels([])\n",
    "ax_actual.set_xticks([])\n",
    "ax_actual.set_yticks([])\n",
    "ax_actual.set_title(\n",
    "    'Actual Input image. Label: {label}'.format(label=label))\n",
    "ax_actual.imshow(pixels,\n",
    "                 cmap='gray',\n",
    "                 interpolation='none')\n",
    "\n",
    "ax_prob = fig_actual.add_subplot(122)\n",
    "ax_prob.set_yticks(x_axis)\n",
    "ax_prob.barh(x_axis,\n",
    "             pred_image,\n",
    "             width,\n",
    "             color='blue',\n",
    "             align='center')\n",
    "ax_prob.spines['right'].set_visible(False)\n",
    "ax_prob.spines['top'].set_visible(False)\n",
    "ax_prob.set_ylabel('Digits')\n",
    "ax_prob.set_xlabel('Prediction percentage')\n",
    "ax_prob.set_title('Probabilities of Prediction')\n",
    "fig_actual.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig_conv, ax_conv = plt.subplots(3, 3, figsize=(8, 8))\n",
    "fig_conv.suptitle('Activations of First Convolution Layer')\n",
    "\n",
    "# Normalisation\n",
    "activations = np.array(test[0, :])\n",
    "max_activ = np.max(activations)\n",
    "min_activ = np.min(activations)\n",
    "a = 255/(max_activ-min_activ)\n",
    "b = 255 - a * max_activ\n",
    "pixels = a * activations + b\n",
    "\n",
    "for row in range(3):\n",
    "    for col in range(3):\n",
    "        idx = row*3 + col\n",
    "        im = ax_conv[row, col].imshow(pixels[idx],\n",
    "                                      cmap='gray',\n",
    "                                      interpolation='none')\n",
    "        ax_conv[row, col].set_xticklabels([])\n",
    "        ax_conv[row, col].set_yticklabels([])\n",
    "        ax_conv[row, col].set_xticks([])\n",
    "        ax_conv[row, col].set_yticks([])\n",
    "fig_conv.subplots_adjust(right=0.8)\n",
    "cbar_conv = fig_conv.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "\n",
    "cbar = fig_conv.colorbar(im, cax=cbar_conv, ticks = [100, 150, 220])\n",
    "cbar.ax.set_yticklabels([\"{:.3f}\".format(min_activ),\n",
    "                         \"{:.3f}\".format(min_activ+\n",
    "                                        (max_activ-min_activ)/2),\n",
    "                         \"{:.3f}\".format(max_activ-0.1)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>From the above experiment, we can see that our simple Convolutional Neural Network is able to achieve reasonable accuracy with a single Convolution layer. In the home assignment, you will create a deep Convolutional Neural Network and explore various hyper parameter settings to improve the accuracy. Good luck!</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
